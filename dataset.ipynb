{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhV5ocuu4h+xITT7pFu697",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreeman-11021996/Fashion-Recommendation-system/blob/main/dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install import_ipynb\n",
        "import import_ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmeGkXWUmYAK",
        "outputId": "8a64384f-67ae-449a-9269-1320f4c09f4a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.7/dist-packages (0.1.4)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (7.9.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import_ipynb) (5.7.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (57.4.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.18.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import_ipynb) (5.1.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython->import_ipynb) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (0.2.5)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (2.16.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.11.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.13.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import_ipynb) (4.3.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import_ipynb) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import_ipynb) (4.1.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.19.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import_ipynb) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MXWybWJRk9ix"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import math\n",
        "from utils import clean_data_,map_label_dicts\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(df):\n",
        "    # remove rows from the DataFrame which do not have corresponding images\n",
        "\n",
        "    # shuffle the dataframe\n",
        "    # sample(frac=1) -> gives us a shuffled dataset, then we reset the index\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    # 90% for training and 10% for validation\n",
        "    num_train_samples = math.floor(len(df) * 0.90)\n",
        "    num_val_samples = math.floor(len(df) * 0.10)\n",
        "    train_df = df[:num_train_samples].reset_index(drop=True)\n",
        "    val_df = df[-num_val_samples:].reset_index(drop=True)\n",
        "    return train_df, val_df"
      ],
      "metadata": {
        "id": "kLd8LbIOlGyA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionDataset:\n",
        "    def __init__(self,df,labels=[\"gender\",\"masterCategory\",\"subCategory\"]):\n",
        "        df = clean_data_(df)\n",
        "        gender,master,sub = map_label_dicts(df)\n",
        "        self.labels = labels\n",
        "        self.label_mappings(df)\n",
        "\n",
        "        self.num_list_gender = gender\n",
        "        self.num_list_master = master\n",
        "        self.num_list_sub = sub\n",
        "        \n",
        "        # the training transforms and augmentations\n",
        "        self.datagen = ImageDataGenerator(rescale=1./255,horizontal_flip=True,vertical_flip=True,\n",
        "                                          rotation_range = 40,shear_range = 0.2,zoom_range = 0.2,\n",
        "                                          width_shift_range=0.2,height_shift_range = 0.2)\n",
        "       \n",
        "    def label_mappings(self,df):\n",
        "        df[\"classes\"] = df[self.labels].apply(tuple, axis=1)\n",
        "        self.df = df.reset_index()[[\"id\",\"classes\",\"index\"]]\n",
        "          \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def preprocess(self,img_path):\n",
        "        image = image.load_img(img_path,target_size=(224,224))\n",
        "        img_array = image.img_to_array(image)\n",
        "        expanded_img_array = np.expand_dims(img_array, axis=0)\n",
        "        preprocessed_img = expanded_img_array/255\n",
        "        return preprocessed_img\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # one image\n",
        "        root_dir = \"images\"\n",
        "        img_filename = str(self.df['id'][index]) + \".jpg\"\n",
        "        img_path = os.path.join(root_dir,img_filename)\n",
        "\n",
        "        image = self.preprocess(img_path)\n",
        "\n",
        "        cat_gender = self.df['gender'][index]\n",
        "        label_gender = self.num_list_gender[cat_gender]\n",
        "        cat_master = self.df['masterCategory'][index]\n",
        "        label_master = self.num_list_master[cat_master]\n",
        "        cat_sub = self.df['subCategory'][index]\n",
        "        label_sub = self.num_list_sub[cat_sub]\n",
        "        \n",
        "        # image to float32 tensor\n",
        "        image = tensorflow.convert_to_tensor(image, dtype=tensorflow.float32)\n",
        "        # labels to long tensors\n",
        "        label_gender = tensorflow.convert_to_tensor(label_gender, \n",
        "                                                    dtype=tensorflow.long)\n",
        "        label_master = tensorflow.convert_to_tensor(label_master, \n",
        "                                                    dtype=tensorflow.long)\n",
        "        label_sub = tensorflow.convert_to_tensor(label_sub, \n",
        "                                                 dtype=tensorflow.long)\n",
        "        return {\n",
        "            'image': image,\n",
        "            'gender': label_gender,\n",
        "            'master': label_master,\n",
        "            'sub': label_sub\n",
        "        }"
      ],
      "metadata": {
        "id": "SVVzyFMIlJky"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nfiI1DtOnTM1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}